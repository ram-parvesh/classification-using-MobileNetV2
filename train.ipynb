{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfa124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "import os\n",
    "import datetime,time\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from dataset import CustomDatasetFromImages\n",
    "from MobileNet import MobileNetV2\n",
    "\n",
    "\n",
    "writer = SummaryWriter()\n",
    "batch_size=32\n",
    "img_dir ='images'\n",
    "train_annotations_file = \"train.csv\"\n",
    "val_annotations_file = \"val.csv\"\n",
    "\n",
    "transforms = transforms.Compose([transforms.ToPILImage(),\n",
    "                                transforms.Resize([int(224), int(224)]),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "train_dataset = CustomDatasetFromImages(img_dir,train_annotations_file,transforms=transforms )\n",
    "val_dataset = CustomDatasetFromImages(img_dir,val_annotations_file ,transforms=transforms)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True,\n",
    "                                            pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset ,batch_size=batch_size, shuffle=True, pin_memory=False)\n",
    "\n",
    "num_epoch = 50\n",
    "learning_rate = 0.0001\n",
    "input_size = 224\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net = MobileNetV2(width_mult=1).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "total_step = len(train_loader)\n",
    "print(\"Total step: \",total_step)\n",
    "\n",
    "valid_loss_min = np.Inf\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    running_loss = 0.0\n",
    "    # scheduler.step(epoch)\n",
    "    correct = 0\n",
    "    total=0\n",
    "    start_time=datetime.datetime.now()\n",
    "    print(\"Training started at time :{} epoch :{}\".format(start_time,epoch))\n",
    "    for idx ,(images,label) in enumerate(train_loader):\n",
    "        # print(images.size())\n",
    "        images = images.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        outputs =net(images)\n",
    "        loss = criterion(outputs,label)\n",
    "\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        _,pred = torch.max(outputs, dim=1)\n",
    "        correct += torch.sum(pred==label).item()\n",
    "        total += label.size(0)\n",
    "        \n",
    "        if idx % 1000 == 0:\n",
    "            print('Epoch [{}/{}],Step [{}/{}],loss:{:.4f}'.format(epoch+1,num_epoch,idx,total_step,loss.item()))\n",
    "    train_acc.append(100 * correct / total)\n",
    "    train_loss.append(running_loss/total_step)\n",
    "    \n",
    "    writer.add_scalar(\"Training Loss\",(running_loss/total_step),epoch)\n",
    "    writer.add_scalar(\"Training Accuracy\",(100 * correct / total),epoch)\n",
    "    print(f'Training loss: {np.mean(train_loss):.4f}, Training acc: {(100 * correct / total):.4f}\\n')      \n",
    "\n",
    "    correct_t = 0\n",
    "    total_t = 0\n",
    "    batch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        net.eval()    # eval model \n",
    "        for data_t ,target_t in val_loader:\n",
    "            data_t = data_t.to(device)\n",
    "            target_t = target_t.to(device)\n",
    "            outputs_t = net(data_t)\n",
    "\n",
    "            # print(\"outputs data\",outputs.data)\n",
    "            loss_t = criterion(outputs_t, target_t)\n",
    "            batch_loss += loss_t.item()\n",
    "            _,pred_t = torch.max(outputs_t, dim=1)\n",
    "            correct_t += torch.sum(pred_t==target_t).item()\n",
    "            total_t += target_t.size(0)\n",
    "        val_acc.append(100 * correct_t / total_t)\n",
    "        val_loss.append(batch_loss/len(val_loader))\n",
    "        network_learned = batch_loss < valid_loss_min\n",
    "        print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t / total_t):.4f}\\n')\n",
    "        writer.add_scalar(\"validation loss\",(batch_loss/len(val_loader)),epoch)\n",
    "        writer.add_scalar(\"validation Accuracy\",(100 * correct_t / total_t),epoch)\n",
    "    # Save the model checkpoint\n",
    "        if (epoch +1) % 2==0:\n",
    "            torch.save(net.state_dict(), 'result0.000132_'+str(epoch+1)+'_model.pth')\n",
    "\n",
    "writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
